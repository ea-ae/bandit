# Bandit

Experimenting with simple neural networks made from scratch as well as reinforcement learning.

## Features

* Stochastic gradient descent with:
    * Vectorization
    * Momentum
    * L2 regularization
    * Weight initialization
* Layers: dense, convolutional
* Cost functions: quadratic, cross-entropy
* Activation functions: ReLu, leaky ReLu, sigmoid
* Data loaders: MNIST, CIFAR-100, ImageNet

## Results

All the training-testing mini-batches were interleaved proportionally.

MNIST dataset:
* 97.7% testing accuracy in 2 minutes over 3 epochs
* 98.3% testing accuracy in 11 minutes over 15 epochs

## Images

![Screenshot](https://i.imgur.com/OeYNIii.png)
